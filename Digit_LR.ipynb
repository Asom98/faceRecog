{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T15:08:49.905495Z",
     "start_time": "2024-11-17T15:04:33.310543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from image_util import load_digits_images, to_grayscale, to_histgram, to_pca, to_norm, pipe_from_folder_to_norm\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from logistic_regression import cross_validate_model, LogisticRegression\n",
    "\n",
    "# Correct paths to your dataset\n",
    "base_folder = r\"./dataset/digits\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(f\"Start Time {start_time}\")\n",
    "\n",
    "# load and normalize images\n",
    "images, labels = load_digits_images(base_folder)\n",
    "normalize_time = datetime.datetime.now()\n",
    "print(f\"loading time: {normalize_time - start_time}\")\n",
    "\n",
    "# Step 1 - GRAYSCALE\n",
    "grayscale_images = to_grayscale(images)\n",
    "grayscale_time = datetime.datetime.now()\n",
    "print(f\"grayscale time: {grayscale_time - normalize_time}\")\n",
    "\n",
    "# Step 2 - HISTGRAM\n",
    "histgram_images = to_histgram(grayscale_images)\n",
    "histgram_time = datetime.datetime.now()\n",
    "print(f\"histogram time: {histgram_time - grayscale_time}\")\n",
    "\n",
    "# Step 3 - PCA\n",
    "pca_images = to_pca(histgram_images)\n",
    "pca_time = datetime.datetime.now()\n",
    "print(f\"pca time: {pca_time - histgram_time}\")\n",
    "\n",
    "# Step 4 - Normalization\n",
    "norm_images = to_norm(pca_images)\n",
    "norm_time = datetime.datetime.now()\n",
    "print(f\"norm time: {norm_time - pca_time}\")\n",
    "\n",
    "# Step 5 - Encode labels to numerical values\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "# One-hot encode the labels for softmax regression\n",
    "labels_one_hot = np.eye(len(np.unique(labels_encoded)))[labels_encoded]\n",
    "one_hot_time = datetime.datetime.now()\n",
    "print(f\"label Encoding time: {one_hot_time - one_hot_time}\")\n",
    "\n",
    "# Step 6 - # Split into training, validation, and test sets\n",
    "images_train_full, images_test, labels_train_full, labels_test = train_test_split(norm_images, labels_one_hot,\n",
    "                                                                                  test_size=0.2, random_state=42)\n",
    "\n",
    "split_time = datetime.datetime.now()\n",
    "print(f\"split dataset time: {split_time - one_hot_time}\")\n",
    "\n",
    "# Step 7 - Cross validate the model\n",
    "cross_validation_accuracy = cross_validate_model(norm_images, labels_one_hot, num_folds=5)\n",
    "cross_validation_time = datetime.datetime.now()\n",
    "print(f\"cross validation time: {cross_validation_time - split_time}\")\n",
    "\n",
    "# Step 8 - Train the model\n",
    "final_model = LogisticRegression(\n",
    "    input_size=images_train_full.shape[1],\n",
    "    num_classes=labels_train_full.shape[1],\n",
    "    learning_rate=0.1,\n",
    "    regularization=0.001,\n",
    ")\n",
    "final_model.train(images_train_full, labels_train_full, epochs=1000)\n",
    "\n",
    "# save the model\n",
    "print(f\"saving the model state...\")\n",
    "final_model.save_model(\"./digits_model\")\n",
    "\n",
    "train_time = datetime.datetime.now()\n",
    "print(f\"train time: {train_time - cross_validation_time}\")\n",
    "\n",
    "# Step 9 Test the final model\n",
    "labels_test_pred = final_model.predict(images_test)\n",
    "final_accuracy = np.mean(np.argmax(labels_test, axis=1) == labels_test_pred)\n",
    "print(f\"Final Test Accuracy: {final_accuracy}\")\n",
    "testing_time = datetime.datetime.now()\n",
    "print(f\"testing time: {testing_time - train_time}\")\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"End Time: {end_time}\")\n",
    "print(f\"Total Duration: {end_time - start_time}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 2024-11-17 16:04:35.344960\n",
      "Opening folder ./dataset/digits/0 ...\n",
      "Opening folder ./dataset/digits/1 ...\n",
      "Opening folder ./dataset/digits/2 ...\n",
      "Opening folder ./dataset/digits/3 ...\n",
      "Opening folder ./dataset/digits/4 ...\n",
      "Opening folder ./dataset/digits/5 ...\n",
      "Opening folder ./dataset/digits/6 ...\n",
      "Opening folder ./dataset/digits/7 ...\n",
      "Opening folder ./dataset/digits/8 ...\n",
      "Opening folder ./dataset/digits/9 ...\n",
      "loading time: 0:00:49.950902\n",
      "grayscale time: 0:00:19.869458\n",
      "histogram time: 0:01:40.573673\n",
      "pca time: 0:00:07.907141\n",
      "norm time: 0:00:00.042501\n",
      "label Encoding time: 0:00:00\n",
      "split dataset time: 0:00:00.038460\n",
      "Epoch 0, Loss: 2.3036667042858148\n",
      "Epoch 100, Loss: 0.8614715363092479\n",
      "Epoch 200, Loss: 0.6855753297770683\n",
      "Epoch 300, Loss: 0.6206690063616267\n",
      "Epoch 400, Loss: 0.5865979896855918\n",
      "Epoch 500, Loss: 0.5656006378461865\n",
      "Epoch 600, Loss: 0.551414405676085\n",
      "Epoch 700, Loss: 0.5412415765517858\n",
      "Epoch 800, Loss: 0.5336356723422283\n",
      "Epoch 900, Loss: 0.5277703511344882\n",
      "Validation Accuracy for fold: 0.8508466713059615\n",
      "Epoch 0, Loss: 2.315926883002\n",
      "Epoch 100, Loss: 0.858801196417859\n",
      "Epoch 200, Loss: 0.6825634318752308\n",
      "Epoch 300, Loss: 0.6176408510282525\n",
      "Epoch 400, Loss: 0.5835960041836669\n",
      "Epoch 500, Loss: 0.562633827623177\n",
      "Epoch 600, Loss: 0.5484816763844511\n",
      "Epoch 700, Loss: 0.5383384894074985\n",
      "Epoch 800, Loss: 0.5307570259103479\n",
      "Epoch 900, Loss: 0.5249111748456922\n",
      "Validation Accuracy for fold: 0.8360009278589654\n",
      "Epoch 0, Loss: 2.3184413852114623\n",
      "Epoch 100, Loss: 0.8615637954777411\n",
      "Epoch 200, Loss: 0.6854777331645759\n",
      "Epoch 300, Loss: 0.6206400904808218\n",
      "Epoch 400, Loss: 0.5866428076275285\n",
      "Epoch 500, Loss: 0.5657143267273097\n",
      "Epoch 600, Loss: 0.551589286958433\n",
      "Epoch 700, Loss: 0.5414695293186356\n",
      "Epoch 800, Loss: 0.5339092331277643\n",
      "Epoch 900, Loss: 0.5280830296167478\n",
      "Validation Accuracy for fold: 0.8522384597541174\n",
      "Epoch 0, Loss: 2.3026191885782983\n",
      "Epoch 100, Loss: 0.8630294083776588\n",
      "Epoch 200, Loss: 0.6876434049571585\n",
      "Epoch 300, Loss: 0.6227890301376846\n",
      "Epoch 400, Loss: 0.5887292545555203\n",
      "Epoch 500, Loss: 0.5677459793080143\n",
      "Epoch 600, Loss: 0.5535778193042671\n",
      "Epoch 700, Loss: 0.5434246273556539\n",
      "Epoch 800, Loss: 0.5358382485539942\n",
      "Epoch 900, Loss: 0.5299914696876292\n",
      "Validation Accuracy for fold: 0.8550220366504291\n",
      "Epoch 0, Loss: 2.296652022855077\n",
      "Epoch 100, Loss: 0.8553944550916158\n",
      "Epoch 200, Loss: 0.6805310984324874\n",
      "Epoch 300, Loss: 0.615848089847693\n",
      "Epoch 400, Loss: 0.5818965982186591\n",
      "Epoch 500, Loss: 0.5610071057449477\n",
      "Epoch 600, Loss: 0.5469238837026579\n",
      "Epoch 700, Loss: 0.5368462944456744\n",
      "Epoch 800, Loss: 0.5293258108624763\n",
      "Epoch 900, Loss: 0.5235355874834371\n",
      "Validation Accuracy for fold: 0.8415680816515889\n",
      "Average Cross-Validation Accuracy: 0.8471352354442125\n",
      "cross validation time: 0:01:03.505303\n",
      "Epoch 0, Loss: 2.30520904423929\n",
      "Epoch 100, Loss: 0.8610046565711497\n",
      "Epoch 200, Loss: 0.6853569484394685\n",
      "Epoch 300, Loss: 0.6205647176882957\n",
      "Epoch 400, Loss: 0.5865436366790927\n",
      "Epoch 500, Loss: 0.5655708359397106\n",
      "Epoch 600, Loss: 0.5513979202865691\n",
      "Epoch 700, Loss: 0.5412328120360153\n",
      "Epoch 800, Loss: 0.5336315574606428\n",
      "Epoch 900, Loss: 0.5277690730688644\n",
      "saving the model state...\n",
      "train time: 0:00:12.655234\n",
      "Final Test Accuracy: 0.8506147065646021\n",
      "testing time: 0:00:00.002267\n",
      "End Time: 2024-11-17 16:08:49.899298\n",
      "Total Duration: 0:04:14.554338\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-10T18:58:16.422950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "from logistic_regression import LogisticRegression\n",
    "from image_util import pipe_from_folder_to_norm\n",
    "import numpy as np\n",
    "\n",
    "model_filename = \"./digits_model\"\n",
    "base_folder = r\"./dataset/digits\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(f\"load images and normalize\")\n",
    "images_test = pipe_from_folder_to_norm(base_folder)\n",
    "\n",
    "print(f\"loading digits model file: {model_filename}\")\n",
    "model = LogisticRegression.load_model(model_filename)\n",
    "\n",
    "print(f\"predict the images\")\n",
    "labels_test_pred = model.predict(images_test)\n",
    "\n",
    "print(f\"calc accuracy\")\n",
    "final_accuracy = np.mean(np.argmax(labels_test, axis=1) == labels_test_pred)\n",
    "print(f\"Final Test Accuracy: {final_accuracy}\")\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"End Time: {end_time}\")\n",
    "print(f\"Total Duration: {end_time - start_time}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load images and normalize\n",
      "Opening folder ./dataset/digits/0 ...\n",
      "Opening folder ./dataset/digits/1 ...\n",
      "Opening folder ./dataset/digits/2 ...\n",
      "Opening folder ./dataset/digits/3 ...\n",
      "Opening folder ./dataset/digits/4 ...\n",
      "Opening folder ./dataset/digits/5 ...\n",
      "Opening folder ./dataset/digits/6 ...\n",
      "Opening folder ./dataset/digits/7 ...\n",
      "Opening folder ./dataset/digits/8 ...\n",
      "Opening folder ./dataset/digits/9 ...\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
