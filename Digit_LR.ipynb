{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:47:27.701477Z",
     "start_time": "2024-11-16T16:42:59.209912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from image_util import load_digits_images, to_grayscale, to_histgram, to_pca, to_norm\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from logistic_regression import cross_validate_model, LogisticRegression\n",
    "\n",
    "# Correct paths to your dataset\n",
    "base_folder = r\"./dataset/digits\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(f\"Start Time {start_time}\")\n",
    "\n",
    "# load and normalize images\n",
    "images, labels = load_digits_images(base_folder)\n",
    "normalize_time = datetime.datetime.now()\n",
    "print(f\"loading time: {normalize_time - start_time}\")\n",
    "\n",
    "# Step 1 - GRAYSCALE\n",
    "grayscale_images = to_grayscale(images)\n",
    "grayscale_time = datetime.datetime.now()\n",
    "print(f\"grayscale time: {grayscale_time - normalize_time}\")\n",
    "\n",
    "# Step 2 - HISTGRAM\n",
    "histgram_images = to_histgram(grayscale_images)\n",
    "histgram_time = datetime.datetime.now()\n",
    "print(f\"histogram time: {histgram_time - grayscale_time}\")\n",
    "\n",
    "# Step 3 - PCA\n",
    "pca_images = to_pca(histgram_images)\n",
    "pca_time = datetime.datetime.now()\n",
    "print(f\"pca time: {pca_time - histgram_time}\")\n",
    "\n",
    "# Step 4 - Normalization\n",
    "norm_images = to_norm(pca_images)\n",
    "norm_time = datetime.datetime.now()\n",
    "print(f\"norm time: {norm_time - pca_time}\")\n",
    "\n",
    "# Step 5 - Encode labels to numerical values\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "# One-hot encode the labels for softmax regression\n",
    "labels_one_hot = np.eye(len(np.unique(labels_encoded)))[labels_encoded]\n",
    "one_hot_time = datetime.datetime.now()\n",
    "print(f\"label Encoding time: {one_hot_time - one_hot_time}\")\n",
    "\n",
    "# Step 6 - # Split into training, validation, and test sets\n",
    "images_train_full, images_test, labels_train_full, labels_test = train_test_split(norm_images, labels_one_hot,\n",
    "                                                                                  test_size=0.2, random_state=42)\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(images_train_full, labels_train_full,\n",
    "                                                                      test_size=0.2, random_state=42)\n",
    "split_time = datetime.datetime.now()\n",
    "print(f\"split dataset time: {split_time - one_hot_time}\")\n",
    "\n",
    "# Step 7 - Cross validate the model\n",
    "cross_validation_accuracy = cross_validate_model(norm_images, labels_one_hot, num_folds=5)\n",
    "cross_validation_time = datetime.datetime.now()\n",
    "print(f\"cross validation time: {cross_validation_time - split_time}\")\n",
    "\n",
    "# Step 8 - Train the model\n",
    "final_model = LogisticRegression(input_size=images_train_full.shape[1],\n",
    "                                 num_classes=labels_train_full.shape[1],\n",
    "                                 learning_rate=0.1,\n",
    "                                 regularization=0.001)\n",
    "\n",
    "final_model.train(images_train_full, labels_train_full, epochs=1000)\n",
    "\n",
    "# save the model\n",
    "final_model\n",
    "train_time = datetime.datetime.now()\n",
    "print(f\"train time: {train_time - cross_validation_time}\")\n",
    "\n",
    "# Step 9 Test the final model\n",
    "labels_test_pred = final_model.predict(images_test)\n",
    "final_accuracy = np.mean(np.argmax(labels_test, axis=1) == labels_test_pred)\n",
    "print(f\"Final Test Accuracy: {final_accuracy}\")\n",
    "testing_time = datetime.datetime.now()\n",
    "print(f\"testing time: {testing_time - train_time}\")\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"End Time: {end_time}\")\n",
    "print(f\"Total Duration: {end_time - start_time}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 2024-11-16 17:43:01.612561\n",
      "Opening folder ./dataset/digits/0 ...\n",
      "Opening folder ./dataset/digits/1 ...\n",
      "Opening folder ./dataset/digits/2 ...\n",
      "Opening folder ./dataset/digits/3 ...\n",
      "Opening folder ./dataset/digits/4 ...\n",
      "Opening folder ./dataset/digits/5 ...\n",
      "Opening folder ./dataset/digits/6 ...\n",
      "Opening folder ./dataset/digits/7 ...\n",
      "Opening folder ./dataset/digits/8 ...\n",
      "Opening folder ./dataset/digits/9 ...\n",
      "loading time: 0:00:43.948185\n",
      "grayscale time: 0:00:15.849489\n",
      "histogram time: 0:02:14.828673\n",
      "pca time: 0:00:05.727676\n",
      "norm time: 0:00:00.036328\n",
      "label Encoding time: 0:00:00\n",
      "split dataset time: 0:00:00.029070\n",
      "Epoch 0, Loss: 2.3160359781402438\n",
      "Epoch 100, Loss: 0.85908586812031\n",
      "Epoch 200, Loss: 0.6843246591930068\n",
      "Epoch 300, Loss: 0.6200188077297538\n",
      "Epoch 400, Loss: 0.586283369829932\n",
      "Epoch 500, Loss: 0.5655067266929087\n",
      "Epoch 600, Loss: 0.5514862545285053\n",
      "Epoch 700, Loss: 0.5414495158674457\n",
      "Epoch 800, Loss: 0.5339615983712168\n",
      "Epoch 900, Loss: 0.5282019047074813\n",
      "Validation Accuracy for fold: 0.8443516585479007\n",
      "Epoch 0, Loss: 2.312643929431405\n",
      "Epoch 100, Loss: 0.8560258322009423\n",
      "Epoch 200, Loss: 0.681904416502755\n",
      "Epoch 300, Loss: 0.6178606297558445\n",
      "Epoch 400, Loss: 0.5842952034447019\n",
      "Epoch 500, Loss: 0.5636441097501322\n",
      "Epoch 600, Loss: 0.5497200424533274\n",
      "Epoch 700, Loss: 0.5397585267498568\n",
      "Epoch 800, Loss: 0.5323298173161525\n",
      "Epoch 900, Loss: 0.5266169619411074\n",
      "Validation Accuracy for fold: 0.8362328926003247\n",
      "Epoch 0, Loss: 2.313580841711126\n",
      "Epoch 100, Loss: 0.8587035174765713\n",
      "Epoch 200, Loss: 0.6844712271854244\n",
      "Epoch 300, Loss: 0.6203016942272275\n",
      "Epoch 400, Loss: 0.5866493590946815\n",
      "Epoch 500, Loss: 0.5659430437499618\n",
      "Epoch 600, Loss: 0.5519849285241712\n",
      "Epoch 700, Loss: 0.5420030419884722\n",
      "Epoch 800, Loss: 0.5345627516700805\n",
      "Epoch 900, Loss: 0.5288439637482344\n",
      "Validation Accuracy for fold: 0.8475991649269311\n",
      "Epoch 0, Loss: 2.2959847939242697\n",
      "Epoch 100, Loss: 0.8606020197909854\n",
      "Epoch 200, Loss: 0.6866000573893529\n",
      "Epoch 300, Loss: 0.6223765798170765\n",
      "Epoch 400, Loss: 0.5886896920499847\n",
      "Epoch 500, Loss: 0.5679588624424775\n",
      "Epoch 600, Loss: 0.5539800882617207\n",
      "Epoch 700, Loss: 0.5439797928518836\n",
      "Epoch 800, Loss: 0.5365231353028341\n",
      "Epoch 900, Loss: 0.5307900789595511\n",
      "Validation Accuracy for fold: 0.8538622129436325\n",
      "Epoch 0, Loss: 2.310739755327148\n",
      "Epoch 100, Loss: 0.8546142247218294\n",
      "Epoch 200, Loss: 0.6804795454803887\n",
      "Epoch 300, Loss: 0.6162079873015911\n",
      "Epoch 400, Loss: 0.5824758031652345\n",
      "Epoch 500, Loss: 0.5617246729730284\n",
      "Epoch 600, Loss: 0.5477453138664882\n",
      "Epoch 700, Loss: 0.5377559691417245\n",
      "Epoch 800, Loss: 0.530315869748996\n",
      "Epoch 900, Loss: 0.524601344075815\n",
      "Validation Accuracy for fold: 0.8401762932034331\n",
      "Average Cross-Validation Accuracy: 0.8444444444444443\n",
      "cross validation time: 0:00:54.717944\n",
      "Epoch 0, Loss: 2.3078429579594553\n",
      "Epoch 100, Loss: 0.8590711589363959\n",
      "Epoch 200, Loss: 0.6844983062895432\n",
      "Epoch 300, Loss: 0.6201777272353367\n",
      "Epoch 400, Loss: 0.5864168572833497\n",
      "Epoch 500, Loss: 0.5656178976030495\n",
      "Epoch 600, Loss: 0.5515791846535174\n",
      "Epoch 700, Loss: 0.54152766804068\n",
      "Epoch 800, Loss: 0.5340277264378042\n",
      "Epoch 900, Loss: 0.5282581779109337\n",
      "train time: 0:00:10.925744\n",
      "Final Test Accuracy: 0.8445836232892601\n",
      "testing time: 0:00:00.002462\n",
      "End Time: 2024-11-16 17:47:27.690082\n",
      "Total Duration: 0:04:26.077521\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
